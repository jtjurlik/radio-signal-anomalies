{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    api_key = config[\"meteo_api\"]\n",
    "\n",
    "save_dir = os.path.join(config[\"data_path\"], \"meteo_raw\")\n",
    "data_dir = config[\"data_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import KPI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cell       lat      lon  Height  Azimuth  nearest_station  station_lat  \\\n",
      "0  322_0  51.93255  6.57633    28.3       80             6283      52.0678   \n",
      "1  322_1  51.93255  6.57633    28.3      190             6283      52.0678   \n",
      "2  322_2  51.93255  6.57633    28.3      320             6283      52.0678   \n",
      "3  168_0  52.63140  4.72566    30.5       60             6233      52.4819   \n",
      "4  168_1  52.63140  4.72566    30.5      180             6233      52.4819   \n",
      "\n",
      "   station_lon  station_height  distance_km  \n",
      "0       6.6567           29.07    17.463337  \n",
      "1       6.6567           29.07    17.463337  \n",
      "2       6.6567           29.07    17.463337  \n",
      "3       4.7258           -1.60    16.594507  \n",
      "4       4.7258           -1.60    16.594507  \n",
      "Number of unique weather stations: 37\n"
     ]
    }
   ],
   "source": [
    "# Load BTS Spatial Data to get the list of relevant weather stations\n",
    "bts_spatial = pd.read_csv(os.path.join(data_dir, \"spatial_new.csv\"))\n",
    "print(bts_spatial.head())\n",
    "\n",
    "# Get unique station IDs needed\n",
    "unique_stations = set(bts_spatial[\"nearest_station\"].astype(str))\n",
    "print(f\"Number of unique weather stations: {len(unique_stations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  timestamp  cell_id  bts  antenna  carrier  minRSSI  \\\n",
      "0 2023-09-02 22:00:00+00:00  166_1_0  166        1        0  -106.62   \n",
      "1 2023-09-02 22:00:00+00:00  168_1_1  168        1        1  -102.35   \n",
      "2 2023-09-02 22:00:00+00:00  168_2_0  168        2        0   -94.60   \n",
      "3 2023-09-02 22:00:00+00:00  168_2_1  168        2        1  -100.00   \n",
      "4 2023-09-02 22:00:00+00:00  174_2_1  174        2        1  -103.89   \n",
      "\n",
      "   pageSessions     ULvol  sessionSetupDur  sessionDur  blocks  anomaly  \n",
      "0          37.0  0.086723         8.362069    8.862069       0        0  \n",
      "1          28.0  0.051203         6.545455    7.090909       0        0  \n",
      "2          19.0  0.036644         8.866667    9.433333       0        1  \n",
      "3           6.0  0.033116         0.000000    0.000000       0        1  \n",
      "4          10.0  0.017862        61.000000   63.500000       0        0  \n"
     ]
    }
   ],
   "source": [
    "# Load KPI dataset\n",
    "kpi_df = pd.read_csv(os.path.join(data_dir, \"cell_undersampled_2.csv\"), parse_dates=[\"timestamp\"])\n",
    "\n",
    "kpi_df.rename(columns={'cell': 'cell_id'}, inplace=True)\n",
    "\n",
    "# Convert timestamps to UTC to match Meteo data (assuming KPI data is in Dutch local time)\n",
    "kpi_df[\"timestamp\"] = kpi_df[\"timestamp\"].dt.tz_localize(\"Europe/Amsterdam\").dt.tz_convert(\"UTC\")\n",
    "print(kpi_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first five characters from the 'cell' column in kpi_df for matching\n",
    "kpi_df['cell_prefix'] = kpi_df['cell_id'].str[:5]\n",
    "\n",
    "# Merge the nearest_station column from bts_spatial to kpi_df based on matching cell_prefix and cell\n",
    "kpi_df = kpi_df.merge(bts_spatial[['nearest_station', 'cell']], left_on='cell_prefix', right_on='cell', how='left')\n",
    "\n",
    "# Drop the temporary cell_prefix column\n",
    "kpi_df.drop(columns=['cell_prefix', 'cell'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  timestamp  cell_id  bts  antenna  carrier  minRSSI  \\\n",
      "0 2023-09-02 22:00:00+00:00  166_1_0  166        1        0  -106.62   \n",
      "1 2023-09-02 22:00:00+00:00  168_1_1  168        1        1  -102.35   \n",
      "2 2023-09-02 22:00:00+00:00  168_2_0  168        2        0   -94.60   \n",
      "\n",
      "   pageSessions     ULvol  sessionSetupDur  sessionDur  blocks  anomaly  \\\n",
      "0          37.0  0.086723         8.362069    8.862069       0        0   \n",
      "1          28.0  0.051203         6.545455    7.090909       0        0   \n",
      "2          19.0  0.036644         8.866667    9.433333       0        1   \n",
      "\n",
      "   nearest_station  \n",
      "0             6344  \n",
      "1             6233  \n",
      "2             6233  \n",
      "\n",
      "                       timestamp  cell_id  bts  antenna  carrier  minRSSI  \\\n",
      "395913 2024-09-22 21:30:00+00:00  603_2_1  603        2        1  -104.85   \n",
      "\n",
      "        pageSessions     ULvol  sessionSetupDur  sessionDur  blocks  anomaly  \\\n",
      "395913          31.0  0.192133         11.52381   12.392857       0        0   \n",
      "\n",
      "        nearest_station  \n",
      "395913             6237  \n"
     ]
    }
   ],
   "source": [
    "print(kpi_df.head(3))\n",
    "print()\n",
    "print(kpi_df.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download needed meteo datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API parameters for downloading only the required data\n",
    "api_url = \"https://api.dataplatform.knmi.nl/open-data/v1/datasets/Actuele10mindataKNMIstations/versions/2/files\"\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "start_date = \"2023-09-02T22:00:00+00:00\"\n",
    "end_date = \"2024-09-22T21:30:00+00:00\"\n",
    "params = {\"begin\": start_date, \"end\": end_date, \"orderBy\": \"created\"}\n",
    "\n",
    "# Convert start_date and end_date to datetime objects\n",
    "start_datetime = datetime.strptime(start_date, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "end_datetime = datetime.strptime(end_date, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "\n",
    "samplevar = \"tx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch files in the date range\n",
    "response = requests.get(api_url, headers=headers, params=params)\n",
    "response.raise_for_status()\n",
    "files = response.json().get(\"files\", [])\n",
    "\n",
    "# Check if files are returned\n",
    "if not files:\n",
    "    print(\"No files found in the specified date range.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309022200.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309022230.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309022300.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309022330.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030000.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030030.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030100.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030130.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030200.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030230.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030300.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030330.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030400.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030430.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030500.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030530.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030600.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030630.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030700.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030730.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030800.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030830.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030900.nc\n",
      "Downloaded: KMDS__OPER_P___10M_OBS_L2_202309030930.nc\n",
      "Download limit reached (24 files). Stopping.\n"
     ]
    }
   ],
   "source": [
    "def download_data(max_files=24):\n",
    "    current_datetime = start_datetime\n",
    "    downloaded_files_count = 0\n",
    "\n",
    "    # Loop through each time window (every 30 minutes) until the end_date\n",
    "    while current_datetime <= end_datetime:\n",
    "        if downloaded_files_count >= max_files:\n",
    "            break\n",
    "\n",
    "        current_datetime_str = current_datetime.strftime(\"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "        \n",
    "        # Define the parameters for the API request\n",
    "        params = {\n",
    "            \"begin\": current_datetime_str,\n",
    "            \"end\": (current_datetime + timedelta(minutes=10)).strftime(\"%Y-%m-%dT%H:%M:%S+00:00\"),\n",
    "            \"orderBy\": \"created\"\n",
    "        }\n",
    "\n",
    "        # Fetch files for the current time window\n",
    "        response = requests.get(api_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        files_data = response.json()\n",
    "        files = files_data.get(\"files\", [])\n",
    "\n",
    "        if not files:\n",
    "            print(f\"No files found for {current_datetime_str}\")\n",
    "        \n",
    "        # Process and download the files for the current time window\n",
    "        for file_info in files:\n",
    "            filename = file_info[\"filename\"]\n",
    "            timestamp_str = filename.split('_')[-1].replace('.nc', '')\n",
    "            minute = int(timestamp_str[10:12])  # Extracts minute part\n",
    "            \n",
    "            # Download only if minute is '00' or '30'\n",
    "            if minute == 0 or minute == 30:\n",
    "        \n",
    "                # Get the download URL\n",
    "                file_url = f\"{api_url}/{filename}/url\"\n",
    "                response = requests.get(file_url, headers=headers)\n",
    "                response.raise_for_status()\n",
    "                download_url = response.json().get(\"temporaryDownloadUrl\")\n",
    "                \n",
    "                # Download and save the file\n",
    "                local_path = os.path.join(save_dir, filename)\n",
    "                file_data = requests.get(download_url)\n",
    "                file_data.raise_for_status()\n",
    "\n",
    "                with open(local_path, \"wb\") as f:\n",
    "                    f.write(file_data.content)\n",
    "\n",
    "                print(f\"Downloaded: {filename}\")\n",
    "                downloaded_files_count += 1  # Increment the download count\n",
    "\n",
    "                # Stop if the download limit is reached\n",
    "                if downloaded_files_count >= 24:\n",
    "                    print(\"Download limit reached (24 files). Stopping.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "        # Increment the current time window by 30 minutes\n",
    "        current_datetime += timedelta(minutes=30)\n",
    "\n",
    "# Start downloading\n",
    "download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract sample vars from meteo datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from /Users/jakobtjurlik/Library/CloudStorage/OneDrive-Personal/Desktop/Study/MSc_Tilburg/MSc Thesis/code/radio-signal-anomalies/data/meteo_raw/KMDS__OPER_P___10M_OBS_L2_202309022200.nc:\n",
      "Station 06201: tx = 16.7\n",
      "Station 06203: tx = 18.2\n",
      "Station 06204: tx = 17.5\n",
      "Station 06205: tx = 16.9\n",
      "Station 06207: tx = 17.5\n",
      "Station 06208: tx = 17.3\n",
      "Station 06209: tx = nan\n",
      "Station 06211: tx = 16.4\n",
      "Station 06214: tx = 17.2\n",
      "Station 06215: tx = 14.4\n"
     ]
    }
   ],
   "source": [
    "def inspect_samplevar(file_path, samplevar='tx', station_var='station'):\n",
    "    # Open the NetCDF file\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    # Extract the samplevar (e.g., 'tx') and station variable\n",
    "    sample_data = ds[samplevar].values\n",
    "    station_data = ds[station_var].values\n",
    "\n",
    "    # Print a snippet of the data (to inspect the values)\n",
    "    print(f\"Sample data from {file_path}:\")\n",
    "    for i in range(min(10, len(sample_data))):  # Limit to the first 10 values or the length of the data\n",
    "        print(f\"Station {station_data[i]}: {samplevar} = {sample_data[i][0]}\")  # Adjusting for shape of sample_data\n",
    "\n",
    "inspect_samplevar(os.path.join(save_dir, \"KMDS__OPER_P___10M_OBS_L2_202309022200.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_tilburg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
