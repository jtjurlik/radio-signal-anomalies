{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1732393050446,
     "user": {
      "displayName": "Jakob Tjurlik",
      "userId": "10339029674418762018"
     },
     "user_tz": -60
    },
    "id": "dD5zQDdqMWLa",
    "outputId": "6401e0d3-fb83-4bbe-fe12-c9c5dcabe950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2390,
     "status": "ok",
     "timestamp": 1732393052826,
     "user": {
      "displayName": "Jakob Tjurlik",
      "userId": "10339029674418762018"
     },
     "user_tz": -60
    },
    "id": "PNY35IV9PKtY",
    "outputId": "e1098d20-7d60-46d8-b390-58f9e3728f6f"
   },
   "outputs": [],
   "source": [
    "!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dazA9FqwLJie"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import utils\n",
    "import keras_tuner as kt\n",
    "\n",
    "utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjTCMXai53r8"
   },
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "LOOKBACK = 24\n",
    "HORIZON = 24\n",
    "N_SPLITS = 4\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI_ddP57fOc5"
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2268,
     "status": "ok",
     "timestamp": 1732393055090,
     "user": {
      "displayName": "Jakob Tjurlik",
      "userId": "10339029674418762018"
     },
     "user_tz": -60
    },
    "id": "WXfGKcIefQCJ",
    "outputId": "1c4f36c0-2bad-4f45-d138-de7b9fbfedc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(933661, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'cell', 'bts', 'antenna', 'carrier', 'minRSSI',\n",
       "       'pageSessions', 'ULvol', 'sessionDur', 'blocks', 'AnomalyDay',\n",
       "       'anomaly', 'noise', 'Height', 'Azimuth', 'SectorsPerBts', 'NearbyBts',\n",
       "       'Dist2Coast', 'ClusterId', 'CellsPerBts', 'OverallPageSessions',\n",
       "       'OverallULvol', 'OverallSessionDur', 'OverallBlocks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_folder = os.getenv(\"DATA_PATH\", \"./default_data_path/\")\n",
    "exp_folder = os.getenv(\"MODEL_PATH\", \"./default_model_path/\")\n",
    "\n",
    "df = pd.read_csv(imp_folder + 'cell_multivar.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkao-F3SfUt5"
   },
   "outputs": [],
   "source": [
    "temporal_X = ['pageSessions', 'ULvol', 'sessionDur']\n",
    "static_X = ['Height', 'Azimuth', 'Dist2Coast', 'ClusterId',\n",
    "            'CellsPerBts', 'OverallPageSessions', 'OverallULvol',\n",
    "            'OverallSessionDur', 'OverallBlocks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPkJYqv65-8O"
   },
   "source": [
    "# Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldcRlogr5843"
   },
   "outputs": [],
   "source": [
    "# Time series split function (Expanding Window)\n",
    "def time_series_split(df, n_splits=N_SPLITS, test_size=0.2):\n",
    "    df = df.sort_values('timestamp')\n",
    "    test_split_index = int(len(df) * (1 - test_size))\n",
    "    train_val_df = df.iloc[:test_split_index]\n",
    "    test_df = df.iloc[test_split_index:]\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    splits = [(train_val_df.iloc[train_index], train_val_df.iloc[val_index]) for train_index, val_index in tscv.split(train_val_df)]\n",
    "    return splits, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oS3gb2T6Po6"
   },
   "outputs": [],
   "source": [
    "# Sequence creation for multivariate time series\n",
    "def create_sequences(df, lookback=LOOKBACK, horizon=HORIZON, static_X=static_X, temporal_X=temporal_X):\n",
    "    X, y, anomaly, cell_id = [], [], [], []\n",
    "\n",
    "    # Loop through each unique cell in the dataset\n",
    "    for cell in df['cell'].unique():\n",
    "        # Filter the dataframe for the current cell only\n",
    "        cell_df = df[df['cell'] == cell]\n",
    "\n",
    "        # Generate sequences within this cell's data\n",
    "        for i in range(lookback, len(cell_df) - horizon + 1):\n",
    "            # Lookback sequences with time-variant features\n",
    "            X_seq = cell_df.iloc[i - lookback:i][['minRSSI'] + temporal_X].values\n",
    "\n",
    "            # Repeat static features across lookback window and concatenate to time-variant features\n",
    "            static_seq = cell_df.iloc[i][static_X].values  # Static features for this cell at a single timestep\n",
    "            static_seq = np.tile(static_seq, (lookback, 1))  # Repeat to match lookback window length\n",
    "\n",
    "            # Concatenate time-variant and time-invariant features\n",
    "            X_combined = np.concatenate([X_seq, static_seq], axis=1)\n",
    "\n",
    "            # Target horizon sequence\n",
    "            y_seq = cell_df.iloc[i:i + horizon]['minRSSI'].values\n",
    "            # Anomaly sequences for later evaluation\n",
    "            anomaly_seq = cell_df.iloc[i:i + horizon]['anomaly'].values\n",
    "            # Cell ID for each sequence\n",
    "            cell_seq = cell_df.iloc[i:i + horizon]['cell'].values\n",
    "\n",
    "            # Append sequences to output lists\n",
    "            X.append(X_combined)\n",
    "            y.append(y_seq)\n",
    "            anomaly.append(anomaly_seq)\n",
    "            cell_id.append(cell_seq)\n",
    "\n",
    "    # Convert lists to numpy arrays for model input\n",
    "    return np.array(X), np.array(y), np.array(anomaly), np.array(cell_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4b5g-qa4fvyN"
   },
   "outputs": [],
   "source": [
    "def scale_data_split(train_df, val_df, temporal_features=temporal_X, static_features=static_X):\n",
    "    scaler_temporal = StandardScaler()\n",
    "    scaler_static = MinMaxScaler()\n",
    "    scaler_target = StandardScaler()\n",
    "\n",
    "    # Scale time-variant features\n",
    "    train_df[temporal_features] = scaler_temporal.fit_transform(train_df[temporal_features])\n",
    "    val_df[temporal_features] = scaler_temporal.transform(val_df[temporal_features])\n",
    "\n",
    "    # Scale time-invariant features\n",
    "    train_df[static_features] = scaler_static.fit_transform(train_df[static_features])\n",
    "    val_df[static_features] = scaler_static.transform(val_df[static_features])\n",
    "\n",
    "    # Scale minRSSI separately (target variable)\n",
    "    train_df['minRSSI'] = scaler_target.fit_transform(train_df[['minRSSI']])\n",
    "    val_df['minRSSI'] = scaler_target.transform(val_df[['minRSSI']])\n",
    "\n",
    "    return train_df, val_df, scaler_target, scaler_temporal, scaler_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHHpMuv8MBqO"
   },
   "outputs": [],
   "source": [
    "def tune_multi_lstm(X_train, y_train, max_epochs=EPOCHS):\n",
    "\n",
    "    def build_tunable_lstm(hp):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "        # Add LSTM layers with recurrent dropout\n",
    "        for i in range(hp.Int('num_lstm_layers', min_value=1, max_value=4)):\n",
    "            model.add(LSTM(\n",
    "                units=hp.Choice('units', values=[10, 20, 50, 100]),\n",
    "                activation=hp.Choice('activation', values=['relu', 'tanh']),\n",
    "                return_sequences=True if i < hp.get('num_lstm_layers') - 1 else False,\n",
    "                kernel_regularizer=l2(hp.Choice('l2_regularizer', values=[1e-2, 1e-3, 1e-4])),\n",
    "                recurrent_dropout=hp.Float(f'recurrent_dropout_{i}', min_value=0.1, max_value=0.4, step=0.1)\n",
    "            ))\n",
    "\n",
    "        # Add dense layers\n",
    "        for j in range(hp.Int('num_dense_layers', min_value=1, max_value=3)):\n",
    "            model.add(Dense(units=hp.Choice(f'dense_units_{j}', values=[24, 48, 96, 288])))\n",
    "\n",
    "            # Optional dense layer dropout\n",
    "            if hp.Boolean(f'use_dense_dropout_{j}'):\n",
    "                dense_dropout_rate = hp.Float(f'dense_dropout_rate_{j}', min_value=0.1, max_value=0.3, step=0.1)\n",
    "                model.add(Dropout(dense_dropout_rate))\n",
    "\n",
    "        model.add(Dense(HORIZON))\n",
    "\n",
    "        # Compile model with fixed optimizer (Adam) and tunable loss function\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss=hp.Choice('loss', values=['mse', 'mae'])\n",
    "        )\n",
    "\n",
    "        # Define batch size as a tunable hyperparameter\n",
    "        batch_size = hp.Choice('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "        return model\n",
    "\n",
    "    # Hyperband tuner instance\n",
    "    tuner = kt.Hyperband(\n",
    "        hypermodel=build_tunable_lstm,\n",
    "        objective='val_loss',\n",
    "        max_epochs=max_epochs,\n",
    "        factor=3,\n",
    "        directory='/content/drive/MyDrive/Thesis/Thesis/lstm/multivar_tuning',\n",
    "        project_name='lstm_tuning'\n",
    "    )\n",
    "\n",
    "    # Fit Hyperband tuner to training data\n",
    "    tuner.search(X_train, y_train,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 epochs=max_epochs,\n",
    "                 verbose=1)\n",
    "\n",
    "    # Get best model and hyperparameters\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_params = tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
    "\n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isvcolF8_kWu"
   },
   "source": [
    "# Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1732393055837,
     "user": {
      "displayName": "Jakob Tjurlik",
      "userId": "10339029674418762018"
     },
     "user_tz": -60
    },
    "id": "LunGFPbs_ZEE",
    "outputId": "3284e624-bdb9-4f0f-fe85-f4e12174fe8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1:\n",
      "  Train set shape: (149388, 24)\n",
      "  Validation set shape: (149385, 24)\n",
      "Split 2:\n",
      "  Train set shape: (298773, 24)\n",
      "  Validation set shape: (149385, 24)\n",
      "Split 3:\n",
      "  Train set shape: (448158, 24)\n",
      "  Validation set shape: (149385, 24)\n",
      "Split 4:\n",
      "  Train set shape: (597543, 24)\n",
      "  Validation set shape: (149385, 24)\n",
      "Test set shape: (186733, 24)\n"
     ]
    }
   ],
   "source": [
    "splits, test_set = time_series_split(df, 4)\n",
    "\n",
    "for i, (train, val) in enumerate(splits):\n",
    "    print(f\"Split {i + 1}:\")\n",
    "    print(f\"  Train set shape: {train.shape}\")\n",
    "    print(f\"  Validation set shape: {val.shape}\")\n",
    "\n",
    "print(f\"Test set shape: {test_set.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "6qXfY5FjA8aH"
   },
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "\n",
    "split1, split2, split3, split4 = splits\n",
    "scaled_train, scaled_val, scaler_target, scaler_temporal, scaler_static = scale_data_split(split3[0], split3[1])\n",
    "scalers = {\n",
    "    'scaler_target': scaler_target,\n",
    "    'scaler_temporal': scaler_temporal,\n",
    "    'scaler_static': scaler_static\n",
    "}\n",
    "\n",
    "# Create sequences\n",
    "X_train, y_train, _, _ = create_sequences(scaled_train, LOOKBACK, HORIZON)\n",
    "X_val, y_val, _, _ = create_sequences(scaled_val, LOOKBACK, HORIZON)\n",
    "\n",
    "# Convert to float32 to avoid data type issues\n",
    "X_train, y_train = X_train.astype(np.float32), y_train.astype(np.float32)\n",
    "X_val, y_val = X_val.astype(np.float32), y_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1732393816835,
     "user": {
      "displayName": "Jakob Tjurlik",
      "userId": "10339029674418762018"
     },
     "user_tz": -60
    },
    "id": "mJueLOfBoBSf",
    "outputId": "0bb0ddb4-c4e4-4f21-a39f-ec64b08cfebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (435139, 24, 13), y_train shape: (435139, 24)\n",
      "X_val shape: (136366, 24, 13), y_val shape: (136366, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546606,
     "status": "ok",
     "timestamp": 1732393049044,
     "user": {
      "displayName": "Jakob Tjurlik",
      "userId": "10339029674418762018"
     },
     "user_tz": -60
    },
    "id": "mMwyMP8Wn_ss",
    "outputId": "c9d311e5-e8fb-47d4-ddfa-735812eae9c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 17m 36s]\n",
      "val_loss: 0.3031729459762573\n",
      "\n",
      "Best val_loss So Far: 0.2620237469673157\n",
      "Total elapsed time: 1d 03h 51m 56s\n",
      "{'num_lstm_layers': 1, 'units': 10, 'activation': 'relu', 'l2_regularizer': 0.001, 'recurrent_dropout_0': 0.30000000000000004, 'num_dense_layers': 1, 'dense_units_0': 96, 'use_dense_dropout_0': False, 'loss': 'mae', 'batch_size': 16, 'recurrent_dropout_1': 0.4, 'recurrent_dropout_2': 0.30000000000000004, 'recurrent_dropout_3': 0.30000000000000004, 'dense_units_1': 24, 'use_dense_dropout_1': True, 'dense_units_2': 288, 'use_dense_dropout_2': True, 'dense_dropout_rate_1': 0.1, 'dense_dropout_rate_0': 0.1, 'dense_dropout_rate_2': 0.2, 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0014'}\n"
     ]
    }
   ],
   "source": [
    "# Tune and train the model\n",
    "best_model, best_params = tune_multi_lstm(X_train, y_train)\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
